# PyNN

A pure `numpy` implementation of `layers`, `learning algorithms` and `objective functions` for `neural networks`.

<p align="left">
    <a href="https://www.python.org/">
    <img src="https://img.shields.io/badge/Python-3.9.6-ff69b4.svg" /></a>
    <a href= "https://pytorch.org/">
    <img src="https://img.shields.io/badge/NumPy-1.23.1-2BAF2B.svg" /></a>
</p>

## Layers and Activation Functions

Layers:
1. Linear
2. Convolution (in-progress)

Activation Functions:
1. Sigmoid
2. Softmax
3. ReLU
4. Tanh (in-progress)
5. LeakyReLU

## Learning Algorithms

1. Stochastic Mini-Batch Gradient Descent

## Metrics

1. Area Under the Curve (AUC)

## Objective Functions

1. Mean Squared Error
2. Categorical Cross Entropy


