{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pynn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "def load_minibatches(batch_size=64):\n",
    "    tsfms = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "    trn_set = datasets.MNIST('./data/train', train=True, download=True, transform=tsfms)\n",
    "    trn_loader = DataLoader(trn_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    data = []\n",
    "    for mb in trn_loader:\n",
    "        inputs_t,targets_t = mb\n",
    "        inputs = np.zeros((inputs_t.size(0),784))\n",
    "        targets = np.zeros((inputs_t.size(0),10))\n",
    "        for i in range(0,inputs_t.size(0)):\n",
    "            targets[i,targets_t[i]] = 1.\n",
    "            for j in range(0,28):\n",
    "                for k in range(0,28):\n",
    "                    inputs[i,j*28+k] = inputs_t[i,0,j,k]\n",
    "        data.append((inputs,targets))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary - Test NN:\n",
      "-------------------------\n",
      "Input - \n",
      "Linear Layer: 784 -> 128\n",
      "ReLU Layer: Relu 1\n",
      "Hidden - \n",
      "Output - \n",
      "Linear Layer: 128 -> 10\n",
      "Softmax Layer: Softmax\n",
      "-------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn = pynn.NeuralNetwork(name='Test NN')\n",
    "l1 = pynn.Linear(in_features=784, out_features=128, bias=True, initialization='random', name='Linear 1')\n",
    "a1 = pynn.ReLU(name='Relu 1')\n",
    "l2 = pynn.Linear(in_features=128, out_features=10, bias=True, initialization='random', name='Linear 2')\n",
    "a2 = pynn.Softmax(name='Softmax')\n",
    "\n",
    "nn.add(block_name='input', layer=l1)\n",
    "nn.add(block_name='input', layer=a1)\n",
    "nn.add(block_name='output', layer=l2)\n",
    "nn.add(block_name='output', layer=a2)\n",
    "print(nn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(model, loss, lr, epochs, data):\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.\n",
    "        batches_seen = 0\n",
    "        for minibatch_x, minibatch_y in data:\n",
    "            batches_seen += minibatch_x.shape[0]\n",
    "            minibatch_y_hat = model(minibatch_x)\n",
    "            running_loss += loss(minibatch_y_hat, minibatch_y).sum()\n",
    "            model.backward(loss.backward())\n",
    "            model.update_weights(lr)\n",
    "        print(f'Epoch {epoch + 1} / {epochs} : Loss = {running_loss / batches_seen}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "lr = 0.001\n",
    "input_size = (1, 28, 28)\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_minibatches(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = pynn.CrossEntropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10 : Loss = 1.5620225674789427\n",
      "Epoch 2 / 10 : Loss = 0.803754901210988\n",
      "Epoch 3 / 10 : Loss = 0.606792314027842\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/dhruvsrikanth/Work/Projects/Deep Neural Network/running_example.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dhruvsrikanth/Work/Projects/Deep%20Neural%20Network/running_example.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m SGD(model\u001b[39m=\u001b[39;49mnn, loss\u001b[39m=\u001b[39;49mloss, lr\u001b[39m=\u001b[39;49mlr, epochs\u001b[39m=\u001b[39;49mepochs, data\u001b[39m=\u001b[39;49mdata)\n",
      "\u001b[1;32m/Users/dhruvsrikanth/Work/Projects/Deep Neural Network/running_example.ipynb Cell 8\u001b[0m in \u001b[0;36mSGD\u001b[0;34m(model, loss, lr, epochs, data)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dhruvsrikanth/Work/Projects/Deep%20Neural%20Network/running_example.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m minibatch_x, minibatch_y \u001b[39min\u001b[39;00m data:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dhruvsrikanth/Work/Projects/Deep%20Neural%20Network/running_example.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     batches_seen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m minibatch_x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dhruvsrikanth/Work/Projects/Deep%20Neural%20Network/running_example.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     minibatch_y_hat \u001b[39m=\u001b[39m model(minibatch_x)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dhruvsrikanth/Work/Projects/Deep%20Neural%20Network/running_example.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss(minibatch_y_hat, minibatch_y)\u001b[39m.\u001b[39msum()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dhruvsrikanth/Work/Projects/Deep%20Neural%20Network/running_example.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     model\u001b[39m.\u001b[39mbackward(loss\u001b[39m.\u001b[39mbackward())\n",
      "File \u001b[0;32m~/Work/Projects/Deep Neural Network/pynn/model/nn.py:38\u001b[0m, in \u001b[0;36mNeuralNetwork.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mfor\u001b[39;00m block \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39minput\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhidden\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m     37\u001b[0m     \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks[block]:\n\u001b[0;32m---> 38\u001b[0m         x \u001b[39m=\u001b[39m layer(x)\n\u001b[1;32m     39\u001b[0m y_hat \u001b[39m=\u001b[39m x\n\u001b[1;32m     40\u001b[0m \u001b[39mreturn\u001b[39;00m y_hat\n",
      "File \u001b[0;32m~/Work/Projects/Deep Neural Network/pynn/model/layers/perceptron.py:77\u001b[0m, in \u001b[0;36mLinear.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[39mCompute forward transformation - **y = Wx + b**.\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m**Parameters:**\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39m    `fx`: transformed data.\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcopy(x)\n\u001b[0;32m---> 77\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfx \u001b[39m=\u001b[39m  \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_linear_transformation()\n\u001b[1;32m     78\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfx\n",
      "File \u001b[0;32m~/Work/Projects/Deep Neural Network/pynn/model/layers/perceptron.py:55\u001b[0m, in \u001b[0;36mLinear._linear_transformation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_linear_transformation\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m     50\u001b[0m     \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[39m    Linear transformation - **Z = Wx + b**.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[39m    **Returns:**\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[39m        `Z`: transformed data.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mdot(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "SGD(model=nn, loss=loss, lr=lr, epochs=epochs, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef574ed592a6dbdab0858c01b944dc6986567d7b8fd8c0e360eef0a15e54368c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
