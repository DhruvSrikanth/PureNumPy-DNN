{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pynn\n",
    "from config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "class MNISTDataLoader:\n",
    "    def __init__(self, type: str, batch_size: int, num_workers: int=1, transform: object=None):\n",
    "        \"\"\"\n",
    "        Initialize MNIST data loader.\n",
    "        Params:\n",
    "            batch_size : (type int) batch size of data loader.\n",
    "            num_workers : (type int) number of workers to use for data loader.\n",
    "            transform : (type object) transform to apply to the dataset.\n",
    "        \"\"\"\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.transform = transform\n",
    "        # Type check the type\n",
    "        self.type = type.lower()\n",
    "\n",
    "        # Check if the type is valid\n",
    "        if self.type != 'train' and self.type != 'test':\n",
    "            raise ValueError(f\"Invalid type: {self.type}. Expected 'train' or 'test'.\")\n",
    "        \n",
    "        # Get the dataset\n",
    "        self.dataset = datasets.MNIST(f'./data/{self.type}', train = self.type == 'train', download=True, transform=self.transform)\n",
    "        \n",
    "        # Create the data loader\n",
    "        self.dataloader = DataLoader(dataset=self.dataset, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Get the length of the data loader.\n",
    "        Returns:\n",
    "            len: (type int) length of the data loader.\n",
    "        \"\"\"\n",
    "        return len(self.dataloader)\n",
    "        \n",
    "    def get_dataloader(self):\n",
    "        \"\"\"\n",
    "        Get the data loader.\n",
    "        Returns:\n",
    "            dataloader: (type torch.utils.data.DataLoader) data loader.\n",
    "        \"\"\"\n",
    "        return self.dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform = []\n",
    "transform.append(transforms.ToTensor())\n",
    "transform.append(transforms.Normalize((0.1307,), (0.3081,)))\n",
    "\n",
    "transform = transforms.Compose(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    'train': MNISTDataLoader(type='train', batch_size=config['batch size'], num_workers=config['num workers'], transform=transform).dataloader,\n",
    "    'test': MNISTDataLoader(type='test', batch_size=config['batch size'], num_workers=config['num workers'], transform=transform).dataloader,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = pynn.NeuralNetwork(name='Test NN')\n",
    "l1 = pynn.Linear(in_features=784, out_features=512, bias=True, initialization='random', name='Linear 1')\n",
    "a1 = pynn.Sigmoid(name='Sigmoid 1')\n",
    "l2 = pynn.Linear(in_features=512, out_features=128, bias=True, initialization='random', name='Linear 2')\n",
    "a2 = pynn.Sigmoid(name='Sigmoid 2')\n",
    "l3 = pynn.Linear(in_features=128, out_features=10, bias=True, initialization='random', name='Linear 3')\n",
    "a3 = pynn.Sigmoid(name='Sigmoid 3')\n",
    "nn.add(block_name='input', layer=l1)\n",
    "nn.add(block_name='input', layer=a1)\n",
    "nn.add(block_name='hidden', layer=l2)\n",
    "nn.add(block_name='hidden', layer=a2)\n",
    "nn.add(block_name='output', layer=l3)\n",
    "nn.add(block_name='output', layer=a3)\n",
    "print(nn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = pynn.MSE(name='MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = pynn.Learner(name='Learner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.train(model=nn, train_set=dataloaders['train'], val_set=dataloaders['test'], epochs=config['epochs'], L=loss, lr=config['learning rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.test(model=nn, test_set=dataloaders['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef574ed592a6dbdab0858c01b944dc6986567d7b8fd8c0e360eef0a15e54368c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
